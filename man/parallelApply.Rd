% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{parallelApply}
\alias{parallelApply}
\title{Applies a Function on Each Row or Column of a Matrix in Parallel.}
\usage{
parallelApply(X, MARGIN, FUN, nTasks = nCores,
  nCores = getOption("mc.cores", 2L), ...)
}
\arguments{
\item{X}{A matrix or matrix-like object.}

\item{MARGIN}{The subscripts which the function will be applied over. \code{1}
indicates rows, \code{2} indicates columns.}

\item{FUN}{The function to be applied.}

\item{nTasks}{The number of tasks the problem should be broken into to be
distributed among \code{nCores} cores. Defaults to \code{nCores}.}

\item{nCores}{The number of cores (passed to \code{\link[parallel:mclapply]{parallel::mclapply()}}).
Defaults to the number of cores as detected by \code{\link[parallel:detectCores]{parallel::detectCores()}}.}

\item{...}{Additional arguments to be passed to \code{\link[base:apply]{base::apply()}}.}
}
\description{
Similar to \code{\link[base:apply]{base::apply()}}, but designed to carry out operations in
parallel.  The input matrix \code{X} is broken into \code{nTasks} chunks and passed to
\code{\link[parallel:mclapply]{parallel::mclapply()}} which applies \code{FUN} on either the rows or the columns
of each chunk.
}
\details{
If \code{nTasks} is \code{1}, \code{\link[base:apply]{base::apply()}} will be called directly without
parallelism.
}
\section{Multi-level parallelism}{

Functions with the \code{nCores}, \code{nTasks}, \code{i}, and \code{j} parameters provide
capabilities for both parallel and distributed computing.

For parallel computing, \code{nCores} determines the number of cores the code is
run on, and \code{nTasks} determines into how many tasks the problem is divided
into. \code{nTasks} should be at least as high as \code{nCores} to keep all cores
busy. Memory usage can be an issue for higher values of \code{nCores} and
\code{nTasks} as R is not particularly memory-efficient. As a rule of thumb, at
least around \code{object_size(X) + (nCores * (object_size(X) / nTasks)) + object_size(result)} MB of total memory will be needed for operations on
memory-mapped matrices, not including potential copies of your data that
might be created (for example \code{\link[stats:lsfit]{stats::lsfit()}} runs \code{cbind(1, X)}). \code{i} and
\code{j} can be used to include or exclude certain rows or columns. Internally,
the \code{\link[parallel:mclapply]{parallel::mclapply()}} function is used and therefore parallel computing
will not work on Windows machines.

For distributed computing, \code{i} and \code{j} determine the subset of the input
matrix that the code runs on. In an HPC environment, this can be used not
just to include or exclude certain rows or columns, but also to partition
the task among many nodes rather than cores. Scheduler-specific code and
code to aggregate the results need to be written by the user. It is
recommended to set \code{nCores} and \code{nTasks} to \code{1} as nodes are often cheaper
than cores.
}

\examples{
# Load example data
bg <- BGData:::loadExample()

# Compute standard deviation of columns
parallelApply(X = bg@geno, MARGIN = 2, FUN = sd)
}
\seealso{
\code{\link[=chunkedApply]{chunkedApply()}} if \code{X} is a memory-mapped matrix and too large to
hold in memory.
}
